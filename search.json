[
  {
    "objectID": "misc/index.html",
    "href": "misc/index.html",
    "title": "Misc.",
    "section": "",
    "text": "Replication template with nix (rix): I updated the past replication template to use nix (rix) for package management. This is a more modern and flexible way to manage packages for your research workflow.\nReplication template (legacy): This is the replication template I use for my empirical papers. This template follows DCAS, the Data and Code Availability Standard v1.0 and also follows the Data and Code Availability Policy of the American Economic Association.\n\n\n\n\n\nQuarto working paper template for Economics: [github link] [Blog post]\n\n\n\n\n\nDockerfile for empirical analysis (R, Python, Julia with dependency management setup): [link]"
  },
  {
    "objectID": "misc/index.html#software",
    "href": "misc/index.html#software",
    "title": "Misc.",
    "section": "",
    "text": "Replication template with nix (rix): I updated the past replication template to use nix (rix) for package management. This is a more modern and flexible way to manage packages for your research workflow.\nReplication template (legacy): This is the replication template I use for my empirical papers. This template follows DCAS, the Data and Code Availability Standard v1.0 and also follows the Data and Code Availability Policy of the American Economic Association.\n\n\n\n\n\nQuarto working paper template for Economics: [github link] [Blog post]\n\n\n\n\n\nDockerfile for empirical analysis (R, Python, Julia with dependency management setup): [link]"
  },
  {
    "objectID": "misc/index.html#personal-tips",
    "href": "misc/index.html#personal-tips",
    "title": "Misc.",
    "section": "Personal tips",
    "text": "Personal tips\n\n\nList of tips\n\n\nTravel tips and recommendations (@Seoul, South Korea)"
  },
  {
    "objectID": "misc/index.html#pictures",
    "href": "misc/index.html#pictures",
    "title": "Misc.",
    "section": "Pictures",
    "text": "Pictures\n\nPast profile pictures\nMemorable moments"
  },
  {
    "objectID": "misc/personal/profile_pictures.html",
    "href": "misc/personal/profile_pictures.html",
    "title": "Past profile pictures",
    "section": "",
    "text": "This is a collection of my past profile pictures."
  },
  {
    "objectID": "misc/personal/profile_pictures.html#section",
    "href": "misc/personal/profile_pictures.html#section",
    "title": "Past profile pictures",
    "section": "2025",
    "text": "2025\n\n\n\n\n\n\n@Locust Walk, Wharton Penn"
  },
  {
    "objectID": "misc/personal/profile_pictures.html#section-1",
    "href": "misc/personal/profile_pictures.html#section-1",
    "title": "Past profile pictures",
    "section": "2024",
    "text": "2024\n\n\n\n2024 Connections@Wharton event"
  },
  {
    "objectID": "misc/personal/profile_pictures.html#section-2",
    "href": "misc/personal/profile_pictures.html#section-2",
    "title": "Past profile pictures",
    "section": "2023",
    "text": "2023\n\n\n\nSinchon, Seoul (near Yonsei University)"
  },
  {
    "objectID": "misc/personal/memorable_moments.html",
    "href": "misc/personal/memorable_moments.html",
    "title": "Memorable moments",
    "section": "",
    "text": "This is a collection of my memorable moments."
  },
  {
    "objectID": "misc/personal/memorable_moments.html#section",
    "href": "misc/personal/memorable_moments.html#section",
    "title": "Memorable moments",
    "section": "2025-2026",
    "text": "2025-2026\n\nThanksgiving\n\n\n\nHalloween\n\n\n\n\n\n\n\n\n\n\n\n\nPhilly trade group seminar"
  },
  {
    "objectID": "misc/personal/memorable_moments.html#section-1",
    "href": "misc/personal/memorable_moments.html#section-1",
    "title": "Memorable moments",
    "section": "2024-2025",
    "text": "2024-2025\n\nStanford University\n\n\nSan Francisco\n\n\nBirthday\n\n\nSpring break (Florida keys)\n\n\nChiang Mai, Thailand"
  },
  {
    "objectID": "misc/personal/econ7300.html",
    "href": "misc/personal/econ7300.html",
    "title": "ECON-7300",
    "section": "",
    "text": "This is an informal note to record what I thought about or what I thought was important in the Metrics I class.\n\nGMM\nIf I can only choose one thing to remember in Metrics I, I would definitely choose GMM. This is mostly because many of the methods we learn in Metrics (at least in the first semester) are in the end some specific form of GMM. For example, IV is just a particular type of GMM. Also, I feel lot of the metrics portion of the applied economics papers are just about finding some moment conditions and estimating the model.\n\n\nData cannot speak for itself\nAs long as we are concerned about some endogeneity problem (which is a common problem in economics), we always needs some assumption to move forward. Just having more data will not solve your problem. In order to identify the parameter of interest, we need economic theory to guide us."
  },
  {
    "objectID": "misc/personal/econ6110.html",
    "href": "misc/personal/econ6110.html",
    "title": "ECON-6110",
    "section": "",
    "text": "This is an informal note to record what I thought about or what I thought was important in the Game theory class."
  },
  {
    "objectID": "misc/personal/econ6110.html#hemi-continuity-and-fixed-point-theorem",
    "href": "misc/personal/econ6110.html#hemi-continuity-and-fixed-point-theorem",
    "title": "ECON-6110",
    "section": "Hemi-continuity and fixed point theorem",
    "text": "Hemi-continuity and fixed point theorem\nWhen I was first learned about hemi-continuity in math camp, I was not sure why we need to know this concept. The only intuition I had was that it is sort of a generalization of the continuity definition to correspondence. But after taking the game theory course, I finally realized that we need this condition to apply Kakutani fixed point theorem. FYI, we need kakutani fixed point theorem to prove that Nash eqm exists.\n\nEx-ante, interim, ex-post\nWhen talking about (expected) payoff of agents, it is important to know whether the agents are maximizing ex-ante, interim, or ex-post. For example, revenue equivalence theorem in auction is about equivalence of autioneer’s expected payoff ex-ante, not ex-post. Fortunately, chatgpt did a good job in summarizing the definition in a table.\n\n\n\nNormal form and extensive form\nIt is important to note that the main difference between normal form game and extensive form game is not the timing. That is, fundamental difference between normal form and extensive form game is not whether the agents make decisions at the same time or not. For example, think of a game where agents makes decisions at different timing but they cannot observe others’ actions. In this setting, the game is still a normal form. The game becomes “extensive” when some agents can observe other agents’ actions before making their own decisions. Thus, the main factor that differentiates normal form and extensive form is whether agents make their actions after observing other’s actions.\n\n\nAdverse selection\nI thought it was interesting to learn that the key takeaway from adverse selection isn’t just the presence of information asymmetry between agents, but that this asymmetry impacts other agents’ payoffs. In fact, this is the main factor leading to the presence of adverse selection. In the famous lemon market example, adverse selection will not occur if there were separate and independent dimensions of utility for the seller and buyer.\n\n\nRevenue equivalence theorem\nAlthough I learned this concept in undergraduate micro class, it was still very cool to know that ex-ante expected revenue becomes equivalent for all standard auction games."
  },
  {
    "objectID": "posts/bash-caveats/1 2 3 4 5/index.html",
    "href": "posts/bash-caveats/1 2 3 4 5/index.html",
    "title": "Beware of Bash",
    "section": "",
    "text": "In this post, I list some important precautions and best practices when working with the Bash shell. Note that this will be updated as I find more of it."
  },
  {
    "objectID": "posts/bash-caveats/1 2 3 4 5/index.html#footnotes",
    "href": "posts/bash-caveats/1 2 3 4 5/index.html#footnotes",
    "title": "Beware of Bash",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe IFS variable is a string of special characters that works as delimiters between words. The default value of IFS is space, tab, newline.↩︎\nYou might wonder what 127 and 0 mean in the output. In Bash, every command gives off return code. If it is 0, it means execute code was run without problem. If it has some other values, it means there is something wrong with the command.↩︎"
  },
  {
    "objectID": "posts/asahi-linux/index.html",
    "href": "posts/asahi-linux/index.html",
    "title": "Asahi-linux on Macbook Pro",
    "section": "",
    "text": "If you have been following up my blog posts, you might have guessed that I am slowly transitioning to using Linux. It took a long 3-stage process to get me there. Windows, macOS, and Linux. It was mostly great, even though there were some small annoyances and hastles along the way (dependencies for installing some R packages, setting up Dropbox, etc). But there was another experiment I wanted to try out: setting up Linux on my Macbook Pro (MBP). While I feel that MBP is just getting too overpriced (one of the reasons I started to transition to Linux in the first place), I still love the design and the build quality of the machine. So I decided to give it a try. But as you all know, setting up Linux on Mac is a painful and hardcore process. That’s when I found out about Asahi-linux."
  },
  {
    "objectID": "posts/asahi-linux/index.html#background",
    "href": "posts/asahi-linux/index.html#background",
    "title": "Asahi-linux on Macbook Pro",
    "section": "",
    "text": "If you have been following up my blog posts, you might have guessed that I am slowly transitioning to using Linux. It took a long 3-stage process to get me there. Windows, macOS, and Linux. It was mostly great, even though there were some small annoyances and hastles along the way (dependencies for installing some R packages, setting up Dropbox, etc). But there was another experiment I wanted to try out: setting up Linux on my Macbook Pro (MBP). While I feel that MBP is just getting too overpriced (one of the reasons I started to transition to Linux in the first place), I still love the design and the build quality of the machine. So I decided to give it a try. But as you all know, setting up Linux on Mac is a painful and hardcore process. That’s when I found out about Asahi-linux."
  },
  {
    "objectID": "posts/asahi-linux/index.html#asahi-linux",
    "href": "posts/asahi-linux/index.html#asahi-linux",
    "title": "Asahi-linux on Macbook Pro",
    "section": "Asahi-linux",
    "text": "Asahi-linux\nAsahi-linux is a Linux distribution that is designed to run on Apple Silicon Macs. It is based on Fedora Linux.It is a community-driven project and is not officially supported by Apple.\nAnother good thing about Asahi-linux is that it is completely legal to use. It is not a hack or a jailbreak. Thus, you don’t have to worry about getting your machine banned or your warranty voided. In fact, it is pretty easy to uninstall it so it shouldn’t be much of an issue.\nIt is sort of similar to the good ol’ bootcamp we used to have for Intel Macs for Linux. Basically we are setting up some partition on the disk to run Linux."
  },
  {
    "objectID": "posts/asahi-linux/index.html#caveats",
    "href": "posts/asahi-linux/index.html#caveats",
    "title": "Asahi-linux on Macbook Pro",
    "section": "Caveats",
    "text": "Caveats\nWhile Asahi-linux is amazing, it is not without its caveats. Most of it is due to the fact that it is built upon macOS.Let me write down some of them as a warning to others.\n\nIt is not officially supported by Apple. So you might not get the best support from Apple.\nReverse engineering is not yet fully accomplished. Some features are not yet available (USB-C display, touchid, etc).\nIt is not yet as stable as macOS. So you might encounter some issues.\nCurrently, only M1 and M2 chips are supported. If you have an older machine or newer chips, it will not work.\nDue to ARM architecture, you cannot run x86_64 applications. So some softwares may not work in Asahi-linux."
  },
  {
    "objectID": "posts/asahi-linux/index.html#setting-up-asahi-linux",
    "href": "posts/asahi-linux/index.html#setting-up-asahi-linux",
    "title": "Asahi-linux on Macbook Pro",
    "section": "Setting up Asahi-linux",
    "text": "Setting up Asahi-linux\n\nFirst, make sure your machine is compatible with Asahi-linux. You can check the Asahi-linux website for the list of compatible machines.\nAlso make sure you have enough disk space. Asahi-linux is a bit larger than macOS. You need to have at least 100GB of free space.\nUse the following command in terminal:\n\n\ncurl https://alx.sh | sh\n\n\nFollow the instructions in the terminal. It will guide you through the process of setting up Asahi-linux.1\n\n\nYour machine will reboot and you will see the option to boot into Asahi-linux.\nIf you need to boot into macOS, turn the power off and hold the power button until “loading startup options…” appears. Then select “macOS” and press enter.\nYou are all set!"
  },
  {
    "objectID": "posts/asahi-linux/index.html#current-experience",
    "href": "posts/asahi-linux/index.html#current-experience",
    "title": "Asahi-linux on Macbook Pro",
    "section": "Current experience",
    "text": "Current experience\nFor now, I am early in the game and trying out the power of Asahi-linux. I will probably use it as my additional machine along with my ThinkPad Ubuntu machine. I will update this section as I go along.\n\nUnlike Ubuntu, it is hard to install Dropbox. But fear not, there is a workaround. Try out maestral instead. For some reason, Docker image installation option did not work for me but python version worked fine."
  },
  {
    "objectID": "posts/asahi-linux/index.html#footnotes",
    "href": "posts/asahi-linux/index.html#footnotes",
    "title": "Asahi-linux on Macbook Pro",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt is very important to exactly follow the instructions in the terminal. If you don’t, you might end up with a broken system. e.g. I struggled a bit on my first try because I did not hold the power button until “loading startup options…” appeared.↩︎"
  },
  {
    "objectID": "posts/make-file/index.html",
    "href": "posts/make-file/index.html",
    "title": "Makefile: build automation software",
    "section": "",
    "text": "If you haven’t used Make yet, you should do it now! Make is a software that can help your research worfklow by automating certain procedures. For example, you can use Make to re-run all your necessary codes whenever there is a change in the raw data in your folder.\nBelow I provide a very simple example of Makefile which is used to run Make. The code below checks all the folders that have git installed and can do git pull and git push for all the folders instead of manually going into the subfolders and run the command separately.\nENJOY!\n\n.PHONY: pull-all push-all\n\nSUBDIRS := $(shell find . -mindepth 1 -maxdepth 1 -type d)\n\npull-all:\n    @for dir in $(SUBDIRS); do \\\n        if [ -d \"$$dir/.git\" ]; then \\\n            echo \"Pulling in $$dir...\"; \\\n            (cd $$dir && git pull); \\\n        else \\\n            echo \"Skipping $$dir (not a git repo)\"; \\\n        fi \\\n    done\n\npush-all:\n    @for dir in $(SUBDIRS); do \\\n        if [ -d \"$$dir/.git\" ]; then \\\n            echo \"Pushing in $$dir...\"; \\\n            (cd $$dir && git push); \\\n        else \\\n            echo \"Skipping $$dir (not a git repo)\"; \\\n        fi \\\n    done"
  },
  {
    "objectID": "posts/dockerfile-trial/index.html",
    "href": "posts/dockerfile-trial/index.html",
    "title": "My trial and error with Dockerfile",
    "section": "",
    "text": "I had a chance to create a replication package for my coding assignment this fall. While doing the assignment, I decided to use this opportunity to actually implement a Dockerfile that will work for most of the platforms (e.g. macOC, Linux, ARM/AMD architecture). This is a post on my trial and error on building Docker image with Dockerfile."
  },
  {
    "objectID": "posts/dockerfile-trial/index.html#r-specific-incompatible-binary-issue-with-certain-packages",
    "href": "posts/dockerfile-trial/index.html#r-specific-incompatible-binary-issue-with-certain-packages",
    "title": "My trial and error with Dockerfile",
    "section": "(R specific) Incompatible binary issue with certain packages",
    "text": "(R specific) Incompatible binary issue with certain packages\nIf you have used linux, you would be very familiar with some of the installtion issues with R packages. It just take awful long time to install most of the packages in linux. The reasn is simple: unlike Windows or MacOS, lot of the packages do not have pre-compiled binary for linux. This is sort of due to the fact that there are so many different linux distributions. As Windows or MacOS is a popular OS (Ugh…), it is easier to maintain standard binary for them. However, this is not the case of linux. Due to this reason, linux users need to compile the source code of the package and literally create the binary for the package. Since most of the powerful packages require compilation (they use C/C++/Fortran for creating efficient package), it is not a surprise that it takes a long time to install the package. Even worse, sometimes compilation does not work because you do not have the necessary compilers or necessary system libraries. This means you need to pre-install all the necessary dependencies before compiling the package.\nFortunately, this issue was recently solved through the help of Rstudio (Posit) Public Package Manager. This is a service that provides fall installtion of binary R packages for linux. Nowadays, most of the packages have their binary counterpart for linux. Thus, you can significantly reduce the time to install the package.\nThe problem however, is that the package manager is not perfect. I am not exactly sure why, but it seems binary might not work for some newer version of linux distribution if they were built from some different version of system libraries. This seems to be case for packages like sf and stringi.\nSo how can we solve this? Well if you are using renv R package as your package dependency manager, you can simply use the following command in your Dockerfile to override the repository written in the renv.lock file:\n\nENV RENV_CONFIG_REPOS_OVERRIDE=https://packagemanager.posit.co/cran/__linux__/noble/latest\n\nThis command will override the repository and install the packages from repository based on certain linux distribution you are using. In this case, I set it to noble which is the Ubuntu 24.04 LTS. This goes nicely with R Rocker project and GitHub Actions because their newest images are based on Ubuntu 24.04 LTS.\nBut there is a caveat: current version (1.1.5) of renv package does not support this feature. This is a known issue (#2127). Fortunately, this was resolved but the newer version is not yet released. For now, you need to use the development version of renv package.1 You can install it by running the following command:\n\nRUN R -e \"install.packages('renv', repos = 'https://posit.r-universe.dev')\""
  },
  {
    "objectID": "posts/dockerfile-trial/index.html#multi-platform-issue",
    "href": "posts/dockerfile-trial/index.html#multi-platform-issue",
    "title": "My trial and error with Dockerfile",
    "section": "Multi-platform issue",
    "text": "Multi-platform issue\nGoing deep into reproducibility is that you need to realize that there are two main CPU architecture: amd64 (x86_64) and aarch64 (arm64). The problem is that base Docker images built on certain CPU platform will not work for the other platform. Also, there are cases where different architecture will require different binary to install certain software. That is, some binary built for amd64 will not work for aarch64 and vice versa.\nWhy should we care about this? Well, the reason is simple: both of the architecture are widely used in the world. amd64 is very common architecture for many types of computers. aarch64 is also a very common architecture. In fact, you are using aarch64 architecture if you are using an Apple Silicon Mac. So the big problem is that if you are using a base Docker image built on amd64, it may not work for people using MacOS.\nFortunately, solution is simple: build both amd64 and aarch64 images. You can do this locally using docker buildx command or you can use this GitHub Actions yaml file:\n\nname: build_docker\n\non:\n  push:\n    branches: [ master, main ]\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    env:\n      IMAGE_NAME: r_4.5.1   # repo name on Docker Hub: DOCKERHUB_USERNAME/r_4.5.1\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      # Enable QEMU so we can cross-build arm64 on amd64 runners\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      # Set up Buildx builder\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Login to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Build and push (multi-arch) base Dockerfile\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          file: ./Dockerfile\n          platforms: linux/amd64,linux/arm64   # &lt;-- key line\n          push: true\n          # tag strategy: latest + branch + short sha\n          tags: |\n            ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.IMAGE_NAME }}:latest\n            ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.IMAGE_NAME }}:${{ github.ref_name }}\n            ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.IMAGE_NAME }}:${{ github.ref_name }}-${{ github.sha }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n          pull: true"
  },
  {
    "objectID": "posts/dockerfile-trial/index.html#another-multi-platform-issue-tinytex",
    "href": "posts/dockerfile-trial/index.html#another-multi-platform-issue-tinytex",
    "title": "My trial and error with Dockerfile",
    "section": "Another multi-platform issue: tinytex",
    "text": "Another multi-platform issue: tinytex\nI was also trying to install Quarto because I used it to render my assignment pdf. However, I encountered a problem when I was trying to install tinytex package. Quarto needs tex compiler to render the pdf. One that is used a lot is tinytex because it is a portable and light tex distribution. When I was installing tinytex in amd64 image, it was fine because all I need to do is:\n\nRUN quarto install tinytex\n\nwhich is provided by Quarto command. The issue, however, was when I was trying to same thing for aarch64 image. Apparently, it seems the previous command runs a binary that is based on amd64 architecture. Thus this command cannot install tinytex for aarch64 image. In order to solve this, I created this if statement in the Dockerfile to install tinytex for aarch64 image.\n\n# Quarto\nENV QUARTO_VERSION=1.7.32\nRUN /rocker_scripts/install_quarto.sh\n\n# --- TinyTeX install (arm64 manual, amd64 via Quarto) ---\nRUN set -eux; \\\n  if [ \"$ARCH_TYPE\" = \"arm64\" ]; then \\\n    wget -qO- \"https://yihui.org/tinytex/install-unx.sh\" | sh -s - --admin --no-path; \\\n  else \\\n    quarto install tinytex; \\\n  fi\n\n# Set TinyTeX path\nENV PATH=\"/root/.TinyTeX/bin/aarch64-linux:/root/.TinyTeX/bin/x86_64-linux:${PATH}\"\n\n# Set CTAN mirror for tlmgr\nENV TEXLIVE_REPOSITORY=\"https://ctan.math.illinois.edu/systems/texlive/tlnet\"\n\n# Set repo in tlmgr\nRUN tlmgr option repository \"$TEXLIVE_REPOSITORY\"; \\\n  tlmgr update --self; \\\n  tlmgr update --all\n# -------------------------------------------------------\n\nNote that if you are only making amd64 image, you don’t need to set the tinytex path. I am doing this because in aarch64 image, tinytex is installed manually and path is not set by Quarto command."
  },
  {
    "objectID": "posts/dockerfile-trial/index.html#tinytex-ctan-mirror-error",
    "href": "posts/dockerfile-trial/index.html#tinytex-ctan-mirror-error",
    "title": "My trial and error with Dockerfile",
    "section": "tinytex CTAN mirror error",
    "text": "tinytex CTAN mirror error\nThis was the most annoying issue I encountered. When tinytex encounter tex package that is not installed in the local system, it uses CTAN mirror in install the necessary tex packages. The problem is that the mirror they refer to is very random… So if you don’t set the mirror, it might occasionally connect to stale one and not be able to install the necessary tex packages. To solve this, you just need to manually set the mirror that seems to be “working.” This is done in the previous code block.\nIf you want to look at the full Dockerfile, you can find it here."
  },
  {
    "objectID": "posts/dockerfile-trial/index.html#footnotes",
    "href": "posts/dockerfile-trial/index.html#footnotes",
    "title": "My trial and error with Dockerfile",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLet’s hope the newer version gets released soon…↩︎"
  },
  {
    "objectID": "posts/quarto-paper-template/index.html",
    "href": "posts/quarto-paper-template/index.html",
    "title": "Quarto format Econ. working paper template",
    "section": "",
    "text": "I just dropped a new Quarto format working paper template that is often used in the field of Economics. You can check the rendered pdf demo here. I also have a github repository for this."
  },
  {
    "objectID": "posts/quarto-paper-template/index.html#footnotes",
    "href": "posts/quarto-paper-template/index.html#footnotes",
    "title": "Quarto format Econ. working paper template",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCited from Quarto official website.↩︎"
  },
  {
    "objectID": "posts/parallel/index.html",
    "href": "posts/parallel/index.html",
    "title": "Parallel programming",
    "section": "",
    "text": "In this post, I write down the materials I studied on parallel programming. All the things below are from Grant McDermott’s lecture so none of it should be credited as my work. It is just a reminder post for applying parallel programming."
  },
  {
    "objectID": "posts/parallel/index.html#load-packages",
    "href": "posts/parallel/index.html#load-packages",
    "title": "Parallel programming",
    "section": "Load packages",
    "text": "Load packages\n\n## Load and install the packages that we'll be using today\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tictoc, parallel, pbapply, future, future.apply, tidyverse, \n               hrbrthemes, furrr, RhpcBLASctl, memoise, here)\n## My preferred ggplot2 plotting theme (optional)\ntheme_set(hrbrthemes::theme_ipsum())\n\n## Set future::plan() resolution strategy\nplan(multisession)"
  },
  {
    "objectID": "posts/parallel/index.html#example-1",
    "href": "posts/parallel/index.html#example-1",
    "title": "Parallel programming",
    "section": "Example 1",
    "text": "Example 1\n\n# library(tidyverse) ## Already loaded\n\n## Emulate slow function\nslow_square = \n  function(x = 1) {\n    x_sq = x^2 \n    d = tibble(value = x, value_squared = x_sq)\n    Sys.sleep(2)\n    return(d)\n    }\n\n# library(tictoc) ## Already loaded\n\ntic()\nserial_ex = lapply(1:12, slow_square) %&gt;% bind_rows()\ntoc()\n\n24.084 sec elapsed\n\n\n\n# future::availableCores() ## Another option\ndetectCores()\n\n[1] 10\n\n\nUse future.apply\n\n# library(future.apply)  ## Already loaded\n# plan(multisession)     ## Already set above\n\ntic()\nfuture_ex = future_lapply(1:12, slow_square) %&gt;% bind_rows()\ntoc(log = TRUE)\n\n6.711 sec elapsed\n\n\nExecution time has greatly reduced! The results are also equivalent:\n\nall.equal(serial_ex, future_ex)\n\n[1] TRUE\n\n\npurrr package also has something similar:\n\n# library(furrr)      ## Already loaded\n# plan(multisession)  ## Already set above\n\ntic()\nfurrr_ex = future_map(1:12, slow_square) |&gt; list_rbind()\ntoc()\n\n5.098 sec elapsed"
  },
  {
    "objectID": "posts/parallel/index.html#example-2",
    "href": "posts/parallel/index.html#example-2",
    "title": "Parallel programming",
    "section": "Example 2",
    "text": "Example 2\nThis is another example. I will not run this to save rendering time.\n\n## Set seed (for reproducibility)\nset.seed(1234)\n# Set sample size\nn = 1e6\n\n## Generate a large data frame of fake data for a regression\nour_data = \n  tibble(x = rnorm(n), e = rnorm(n)) %&gt;%\n  mutate(y = 3 + 2*x + e)\n\n## Function that draws a sample of 10,000 observations, runs a regression and\n## extracts the coefficient value on the x variable (should be around 2).\nbootstrp = \n  function(i) {\n  ## Sample the data\n  sample_data = sample_n(our_data, size = 1e4, replace = TRUE)\n  ## Run the regression on our sampled data and extract the extract the x\n  ## coefficient.\n  x_coef = lm(y ~ x, data = sample_data)$coef[2]\n  ## Return value\n  return(tibble(x_coef = x_coef))\n  }\n\nset.seed(123L) ## Optional to ensure that the results are the same\n\n## 10,000-iteration simulation\ntic()\nsim_serial = lapply(1:1e4, bootstrp) %&gt;% bind_rows()\ntoc(log = TRUE)\n\n# Takes about 36 seconds."
  },
  {
    "objectID": "posts/parallel/index.html#summary-of-parallel-programming-packages-in-r",
    "href": "posts/parallel/index.html#summary-of-parallel-programming-packages-in-r",
    "title": "Parallel programming",
    "section": "Summary of parallel programming packages in R",
    "text": "Summary of parallel programming packages in R\nfuture ecosystem is very useful. It provides simple and unified approach to implementing parallel programming. You can usually apply this ecosystem by using future.apply or furrr package."
  },
  {
    "objectID": "posts/parallel/index.html#if-in-linux-or-mac-try-forking",
    "href": "posts/parallel/index.html#if-in-linux-or-mac-try-forking",
    "title": "Parallel programming",
    "section": "If in Linux or Mac, try forking!",
    "text": "If in Linux or Mac, try forking!\nThere two different ways to run parallel programming:\n\n\n\n\n\n\n\nforking\nparallel sockets (PSOCKS)\n\n\n\n\nFast and memory efficient.\nSlower and more memory-intensive (than forking).\n\n\nOnly available for Unix-based systems.\nWorks on every operating system, incl. Windows.\n\n\nPotentially unstable in an IDE like RStudio.\nFine to use in an IDE like RStudio.\n\n\n\nHow to do this\n\nChange your resolution plan to plan(multicore), and\nRun your R script from the terminal using, say, $ Rscript -e 'rmarkdown::render(\"mydoc.Rmd\", \"all\")' or $ Rscript myfile.R."
  },
  {
    "objectID": "posts/parallel/index.html#implicit-parallel-programming",
    "href": "posts/parallel/index.html#implicit-parallel-programming",
    "title": "Parallel programming",
    "section": "Implicit parallel programming",
    "text": "Implicit parallel programming\nSome packages actually apply parallel programming implicitly (e.g. data.table). So in this case, you might not need to resort too much in explicit parallel programming."
  },
  {
    "objectID": "posts/parallel/index.html#setting-how-many-cores-to-use",
    "href": "posts/parallel/index.html#setting-how-many-cores-to-use",
    "title": "Parallel programming",
    "section": "Setting how many cores to use",
    "text": "Setting how many cores to use\nplan(multisession) or plan(multicore) automatically default to using all your cores. You can change that by running, say, plan(multisession(workers = detectCores()-1))."
  },
  {
    "objectID": "posts/reproducible-template/index.html",
    "href": "posts/reproducible-template/index.html",
    "title": "Hands-on reproducible research workflow",
    "section": "",
    "text": "With the replication crisis in social science now widely recognized, it may seem unnecessary to restate the motivation for building reproducible research workflows. Nonetheless, I will re-iterate it here once more for both their importance and the urgency of adopting them—the time for such practices has truly arrived.\nInnovations in computation tools and access to big data have opened a new era for researchers in social science. In terms of theory, such innovations have allowed researchers to create a more rich and flexible model that represent the real world. It also allowed researchers to test their models using the beneifts of wider access to data. In terms of empirical research, researchers can now answer many interesting questions that were not possible before due to the limitations of data availability. But this did not come without a cost. Unfortunately, sudden rise in the computation power and wider access to data were not fully accompanied by the development of best practices in reproducible research. It didn’t take long for researchers to realize that large portion of the academic research had serious issues in reproducibility. Many journals did not have any standard policy for replication package. Many researchers were having hard time in replicating results from published papers. This was a serious issue as it was making the academic research process less transparent and less reliable. In order to address this issue, many journals and researches started to emphasize the need for creating standard for reproducible research.\nHowever, having a reproducible research workflow is not an easy task. It does have some steep learning curve that takes time and effort. This is where this blog post comes in. I will walk you through the process of building a reproducible research workflow. I will also share some tips and personal experiences that I have gathered from my own journey of building a reproducible research workflow."
  },
  {
    "objectID": "posts/reproducible-template/index.html#motivation-why-do-we-need-reproducible-research-workflow",
    "href": "posts/reproducible-template/index.html#motivation-why-do-we-need-reproducible-research-workflow",
    "title": "Hands-on reproducible research workflow",
    "section": "",
    "text": "With the replication crisis in social science now widely recognized, it may seem unnecessary to restate the motivation for building reproducible research workflows. Nonetheless, I will re-iterate it here once more for both their importance and the urgency of adopting them—the time for such practices has truly arrived.\nInnovations in computation tools and access to big data have opened a new era for researchers in social science. In terms of theory, such innovations have allowed researchers to create a more rich and flexible model that represent the real world. It also allowed researchers to test their models using the beneifts of wider access to data. In terms of empirical research, researchers can now answer many interesting questions that were not possible before due to the limitations of data availability. But this did not come without a cost. Unfortunately, sudden rise in the computation power and wider access to data were not fully accompanied by the development of best practices in reproducible research. It didn’t take long for researchers to realize that large portion of the academic research had serious issues in reproducibility. Many journals did not have any standard policy for replication package. Many researchers were having hard time in replicating results from published papers. This was a serious issue as it was making the academic research process less transparent and less reliable. In order to address this issue, many journals and researches started to emphasize the need for creating standard for reproducible research.\nHowever, having a reproducible research workflow is not an easy task. It does have some steep learning curve that takes time and effort. This is where this blog post comes in. I will walk you through the process of building a reproducible research workflow. I will also share some tips and personal experiences that I have gathered from my own journey of building a reproducible research workflow."
  },
  {
    "objectID": "posts/reproducible-template/index.html#documentation",
    "href": "posts/reproducible-template/index.html#documentation",
    "title": "Hands-on reproducible research workflow",
    "section": "Documentation",
    "text": "Documentation\nFirst step of every reproducible research workflow is documentation. Essence of reproducible research workflow is about creating a set of records that can be used by others to reproduced the results of the research. This is basically a researcher talking to other researchers about the detailed steps to reproduce the results of the research. Since we can not physically be present in the other researcher’s office, we need to have a set of records that can be used by others to reproduced the results of the research.\n\nFollow the standard\nWhen in doubt, follow the standard. Fortunately, you don’t need to reinvent the wheel for the necessary documentation for reproducible workflow. In fact, there are many official guidlines that you can consult to. For example, data editors of the journals of the American Economic Association, the Royal Economic Society, the Review of Economic Studies, the Canadian Journal of Economics, and Economic Inquiry have created the Data and Code Availability Standard (DCAS). This standard allows researchers to have a consistent way to document the data and code availability of their research.\nIn my template, I follow the DCAS standard and incorporated it into the README.md file. You can use the example in the README as a template for your own documentation.\n\n\nDocument everything\nWhen in doubt, document everything. Marginal utility of documenting additional information is mostly non-negative for other researchers. Thus, when you are unsure whether this additional information is useful or not, just document it and think later.\n\n\nComment (almost) everything\nWhen in doubt, comment everything in your code. This should also obvious as I am pretty sure you had many experiences of going through someone else’s codes and getting frustrated by 1,000 lines of convoluted codes with no explanations as all.\nFor example, imagine you have to decode this (I know this is a bit extreme…):\n\n#include                                     &lt;math.h&gt;\n#include                                   &lt;sys/time.h&gt;\n#include                                   &lt;X11/Xlib.h&gt;\n#include                                  &lt;X11/keysym.h&gt;\n                                          double L ,o ,P\n                                         ,_=dt,T,Z,D=1,d,\n                                         s[999],E,h= 8,I,\n                                         J,K,w[999],M,m,O\n                                        ,n[999],j=33e-3,i=\n                                        1E3,r,t, u,v ,W,S=\n                                        74.5,l=221,X=7.26,\n                                        a,B,A=32.2,c, F,H;\n                                        int N,q, C, y,p,U;\n                                       Window z; char f[52]\n                                    ; GC k; main(){ Display*e=\n XOpenDisplay( 0); z=RootWindow(e,0); for (XSetForeground(e,k=XCreateGC (e,z,0,0),BlackPixel(e,0))\n; scanf(\"%lf%lf%lf\",y +n,w+y, y+s)+1; y ++); XSelectInput(e,z= XCreateSimpleWindow(e,z,0,0,400,400,\n0,0,WhitePixel(e,0) ),KeyPressMask); for(XMapWindow(e,z); ; T=sin(O)){ struct timeval G={ 0,dt*1e6}\n; K= cos(j); N=1e4; M+= H*_; Z=D*K; F+=_*P; r=E*K; W=cos( O); m=K*W; H=K*T; O+=D*_*F/ K+d/K*E*_; B=\nsin(j); a=B*T*D-E*W; XClearWindow(e,z); t=T*E+ D*B*W; j+=d*_*D-_*F*E; P=W*E*B-T*D; for (o+=(I=D*W+E\n*T*B,E*d/K *B+v+B/K*F*D)*_; p&lt;y; ){ T=p[s]+i; E=c-p[w]; D=n[p]-L; K=D*m-B*T-H*E; if(p [n]+w[ p]+p[s\n]== 0|K &lt;fabs(W=T*r-I*E +D*P) |fabs(D=t *D+Z *T-a *E)&gt; K)N=1e4; else{ q=W/K *4E2+2e2; C= 2E2+4e2/ K\n *D; N-1E4&& XDrawLine(e ,z,k,N ,U,q,C); N=q; U=C; } ++p; } L+=_* (X*t +P*M+m*l); T=X*X+ l*l+M *M;\n  XDrawString(e,z,k ,20,380,f,17); D=v/l*15; i+=(B *l-M*r -X*Z)*_; for(; XPending(e); u *=CS!=N){\n                                   XEvent z; XNextEvent(e ,&z);\n                                       ++*((N=XLookupKeysym\n                                         (&z.xkey,0))-IT?\n                                         N-LT? UP-N?& E:&\n                                         J:& u: &h); --*(\n                                         DN -N? N-DT ?N==\n                                         RT?&u: & W:&h:&J\n                                          ); } m=15*F/l;\n                                          c+=(I=M/ l,l*H\n                                          +I*M+a*X)*_; H\n                                          =A*r+v*X-F*l+(\n                                          E=.1+X*4.9/l,t\n                                          =T*m/32-I*T/24\n                                           )/S; K=F*M+(\n                                           h* 1e4/l-(T+\n                                           E*5*T*E)/3e2\n                                           )/S-X*d-B*A;\n                                           a=2.63 /l*d;\n                                           X+=( d*l-T/S\n                                            *(.19*E +a\n                                            *.64+J/1e3\n                                            )-M* v +A*\n                                            Z)*_; l +=\n                                            K *_; W=d;\n                                            sprintf(f,\n                                            \"%5d  %3d\"\n                                            \"%7d\",p =l\n                                           /1.7,(C=9E3+\n                              O*57.3)%0550,(int)i); d+=T*(.45-14/l*\n                             X-a*130-J* .14)*_/125e2+F*_*v; P=(T*(47\n                             *I-m* 52+E*94 *D-t*.38+u*.21*E) /1e2+W*\n                             179*v)/2312; select(p=0,0,0,0,&G); v-=(\n                              W*F-T*(.63*m-I*.086+m*E*19-D*25-.11*u\n                               )/107e2)*_; D=cos(o); E=sin(o); } }"
  },
  {
    "objectID": "posts/reproducible-template/index.html#data-management",
    "href": "posts/reproducible-template/index.html#data-management",
    "title": "Hands-on reproducible research workflow",
    "section": "Data management",
    "text": "Data management\n\nHave consistent project structure\nMens sana in corpore sano–same for reproducible research workflow. Healthy reproducible habit comes from having a clear, reproducible folder structure for your research. How can you easily automate certain process in your workflow if you don’t know where your raw data is in your folder? You would be very error-prone if you have your source codes everywhere. If you are having hard time following what you did in your own workflow, other people will do much worse. Thus, having a consistent folder structure for your research is one of the first steps of reproducible research workflow.\nFortunately, answer to this is quite simple: setup a consistent project structure. Project structure means you module your research into a project with consistent set of folders. Crucial point about project structure is that everything necessary to run your research should be contained within the project. This includes your source codes, data, environment, etc. This ensures that you isolate the materials for your research from other unnecessary materials that could corrupt your workflow. Within the project parent folder, you should also have some consistent sets of folders that divide files by their functions. For example, you might have src folder to contain all your source codes, input folder for all your data, etc. In fact, this is how my replication template is structured.\n\n\nDon’t directly modify the raw data\nNEVER directly modify the raw data. First, it is very hard to remember how you modified the raw data. If you forget this process, reproducibility of the every subsequent analysis can be severely impaired. Second, if it is hard to for you do re-do this modification, it will be even harder for other replicators. Always use source code and create a new file from the raw data if you want to modify it. If you have no choice but to manually modify the raw data due to some reasons, save the result as a new file instead of overwriting it.\n\n\nAutomate the data download process (if possible)\nHumans are so error-prone. That being said, don’t expect them to be very good at understanding your document. People will always make mistakes. Thus, it is always best to automate certain process in your workflow rather than telling people some instructions in the document.\nOne example of this is the data download process. Instead of manually clicing and downloading the data from the website, you can automate this process by using a bash script. First, locate the data download link in the website. You can get this by right-clicking the link and selecting “Copy link address”. Then, you can write a bash script as follows:\n\n#!/bin/bash\n\nwget -nc -P [file_path] [data_download_link]\n\nwget is a command-line tool that allows you to download files from the internet. -nc option means “no clobber”, which means it will not download the file if it already exists. -P option means “directory path”, which means it will download the file to the specified directory.\nAlso, lot of the bulk data nowadays provide API to download the data using code script. If they provide such API, you can use it to write a script that automatically download the data.\nWe will later discuss it in the build automation section, but I have included this logic in the Makefile file."
  },
  {
    "objectID": "posts/reproducible-template/index.html#coding",
    "href": "posts/reproducible-template/index.html#coding",
    "title": "Hands-on reproducible research workflow",
    "section": "Coding",
    "text": "Coding\n\nSet same environment for all environments\nIf you have been coding for a while, probably you would have experienced either of the following:\n\nMy code works on my computer but not on other people’s computer.\nCode that I wrote 6 months ago does not work anymore because of the new package update.\nMy code that worked on MacOS does not work on Windows.\n\nEven though they look just incidental, these are all very serious issues that can severely impair the reproducibility of your research. How can we trust your results if it does not work after 6 months? In fact, how can we trust your results if it does not even work on your own computer? Thus, it is very important to set the same environment for all environments. You need to ensure that your original environment is portable and can work on any other settings.\nIn general, having reproducible workflow means your code can be run in different environments. Different environments can range from different coding packages to different operating systems. But how can we do this? Best pratice is to always setup your research workflow so that you can setup the environment you used in your research in other people’s computer. This can be usually done by using several tools: Docker, package dependencies manager, etc. We will discuss this in more detail in the upcoming sections.\n\n\nRelative, relative, relative (path)!\nPlease please don’t have something like this in the first line of your source code:\n\nsetwd(\"C:\\Users\\jenny\\path\\that\\only\\I\\have\")\n\nIf you do, I swear I will come to your office and set your computer on fire.\nYou can clearly see that this violates the environment-independent environment principle we were discussing earlier. There is just no chance that other people’s computer will have the same absolute path to the data as yours. Thus, all your codes will break if you embed this directly in your code.\nThen what should we do? The answer is simple: use relative path. Relative path is a path that is relative to the current working directory. For example, if you are in the C:\\Users\\jenny\\path\\that\\only\\I\\have directory, the relative path to the data is data/data.csv. This is because the data is in the data folder.\nWay to implement this is very simple. In case of R, you can use the R project with the here package. here package allows you to use relative path for your research project. All you need to do is to have either R project file or .here file in your project root directory. Then, you can use here() function to get the relative path to the data.\nLet’s suppose that your project has the following structure:\n\nproject/\n├── data/\n├── src/code.R\n├── README.md\n├── .here\n\nusing here package, you can use relative path in your code.R file as follows:\n\nlibrary(here)\ndata_path &lt;- here(\"data\", \"data.csv\")\n\nIn this code, here(\"data\", \"data.csv\") will return something like /home/usrs/project/data/data.csv regardless of the current working directory. Thus, here package takes care of the relative/absolute path issue without you having to worry about it.\nIf you are familiar with the R and the R project, you might be wondering whty you need to use the here package explicitly. After all, if you have the R project, you can juse use the relative path in your code even without using the here() function. There are several reasons. First, other researchers might want to run the code in the terminal. In this case, the terminal not automatically detect the R project file and lead to path errors. Second, using here() function is more robust to different operating systems. For example, Windows and Linux have different path separator. here() function takes care of this issue for you.\nThese sort of project environment are common in many different programming languages. Thus, you should have no problem using this in your own research workflow if you use other programming languages.\n\n\nGet used to shell scripting\nWhy use shell/bash/zsh/terminal, etc? There are several reasons.\n\nIt is more efficient to use shell scripting to automate the process.\n\nSuppose you need to create 100 files names such as file_1.txt, file_2.txt, file_3.txt, …, file_100.txt. You can write a shell script to do this as follows:\n\ntouch file_{1..100}.txt\n\nYou can also delete them all as follows:\n\nrm file_*.txt\n\n\nMany tools used for reproducible research workflow are designed to be used in the terminal. For example, Docker is designed to be used in the terminal. If you are using Docker, it will be lot easier to use it in the terminal. Same for makefiles.\nPowerful tools helpful for your research use terminal as their interface. For example, HPC clusters usually use linux and most of the tools are designed to be work in the terminal.\n\nIn my template, bash will be used a lot in the Makefile file.\n\n\nUse version control\nRemember writing a final version of your documents? final-version.pdf, final-final-version.pdf, really-really-final-version.pdf, etc. This is just inefficient because (1) it is hard to keep track of all the versions, (2) file name is not descriptive enough to know what is the difference between the versions, (3) it is hard to revert to a previous version if you need to, (4) you might accidentally overwrite the previous version if you are not careful.\nSame problem applies to your source code. When you write your code, you will always be changing its content. You might add on to it, delete some parts, or go back and forth between different versions. If you are not careful, this might lead to all sorts of errors. This is where version control systems come in. Version control systems allow you to keep track of all the versions of your code and revert to a previous version if you need to. In the coding world, Git is the industry standard for version control systems. If you don’t know about Git yet, please learn it ASAP. While learning Git, you should also learn about GitHub as it is the most popular platform for hosting Git repositories.\n\n\nUse Docker to “ship” your computer\nDocker is a tool that allows you to create a container that contains all the dependencies for your code. This means that you can “ship” your computer to other people and they can run your code without having to install all the dependencies on their own computer. This is very useful because it is highly likely that other replicators will be using different operating systems and different versions of the software. By using Docker, you can ensure that your code will work on any other computer.\nIf you want to know the basics of Docker, check out this. In my template, I included two Dockerfile files. One is Dockerfile which uses R Rocker project as the base image and installs some necessary system dependencies for installing certain R packages (e.g. sf). It also installs version 1.1.5 of renv package. The other is Dockerfile_r_julia_quarto which is based on my previously mentioned Dockerfile and adds Julia and Quarto. It also takes care of the issue with installing tinytex in AMD and ARM architecture.\n\n\nUse package dependencies managers\nOne of the reasons your old code does not work is because you have a newer version of the package which does not work with your old code. For example, suppose you had a R code that used tidyverse package version 1.0.2. After 2 years, you now have a newer version. Unfortunately, the newer version of the tidyverse package does not work anymore with your old code because there were some changes in the package. This is a very common issue that can seriously impact the reproducibility of your research.\nFortunately, you can use package dependenceis managers to resolve this. Package dependencies managers record the version of the packages being installed and keep track of the dependencies between packages. Thus, you can easily create a new environment that has the same version of the packages as the original environment. Nowadays, most of the programming languages have their own package dependenceis managers. For example, R has renv and Julia has Pkg.\n\n\nUse build automation tools\nIf you have multiple scripts, it is hard to remember which script to run and in what order. This is where build automation tools come in. Build automation tools allow you to define the order of the scripts to run and the dependencies between the scripts. This means that you can run your entire workflow with a single command.\nThere are many build automations tools out there. One of the popular one is GNU Make. For reference, I have my own Makefile file in the template.\n\n\nMake your code invulnerable to “restart session”\nPlease please don’t have something like this in the first line of your source code:\n\nrm(list = ls())\n\nIf you do, I swear I will again come to your office and set your computer on fire.\nThis is because it does not exactly do what you intend to do. When you run this code, you are probably trying to clean up the environment and start from a fresh state. However, this code will not do that. It will only remove the global objects in the environment. That being said, it will still have the non-data portions of the environment. For example, it will still have the packages that you loaded in the environment.\nThen what should we do? Instead of using the above code, you should just restart the whole session. This ensures that your session is completely fresh. It also gives you good discipline since your code should be able to run from a fresh state."
  },
  {
    "objectID": "posts/arch-install/index.html",
    "href": "posts/arch-install/index.html",
    "title": "My first trial and error with installing Arch Linux",
    "section": "",
    "text": "I had some time to try Arch Linux on my Tuxedo Computers InfinityBook Pro 15. It was a bit of a hassle but I managed to get it working. For most of the installation, I followed the Arch Linux installation guide. Fortunately, Arch Linux has a very helpful up-to-date documentation so you will not have much trouble following the guide. However, there were some additional hassle that were not super explicit in the documentation. In this blog, I will try to write them down just for reference."
  },
  {
    "objectID": "posts/arch-install/index.html#creating-a-bootable-usb-drive",
    "href": "posts/arch-install/index.html#creating-a-bootable-usb-drive",
    "title": "My first trial and error with installing Arch Linux",
    "section": "Creating a bootable USB drive",
    "text": "Creating a bootable USB drive\nIn order to install Arch Linux, you need to create a bootable USB drive. There are many options to do this. I used Ventoy which was very intuitive."
  },
  {
    "objectID": "posts/arch-install/index.html#setting-up-wifi",
    "href": "posts/arch-install/index.html#setting-up-wifi",
    "title": "My first trial and error with installing Arch Linux",
    "section": "Setting up wifi",
    "text": "Setting up wifi\nBefore installing Arch Linux, you need to set up wifi first. If you have a wired connection, you can skip this section.\n\n# type iwctl to get into the interactive prompt given by iwd (wireless daemon)\niwctl\n\n# list device names for wireless network connection\nstation list # probably you will see something like wlan0\n\n# scan and get networks available\nstation wlan0 scan\nstation wlan0 get-networks\n\n# enter name for the network\nstation wlan0 connect &lt;network-name&gt;\n\n# enter password for the network when prompted\n\n# exit the iwctl prompt\nexit\n\n# check if the connection is successful\nping -c 4 google.com"
  },
  {
    "objectID": "posts/arch-install/index.html#enabling-wifi-connection-after-installation",
    "href": "posts/arch-install/index.html#enabling-wifi-connection-after-installation",
    "title": "My first trial and error with installing Arch Linux",
    "section": "Enabling wifi connection after installation",
    "text": "Enabling wifi connection after installation\nDuring the installtion, I installed networkmanager to manage wifi connections. You can do this by additionaly installing networkmanager package when you are following the installation guide on pacstrap. Also, make sure to enable the service by running systemctl enable NetworkManager.\nHowever, unlike other installation guide, I found out that the wifi connection was not automatically connected after installation. In order to fix this, you need to run the following command after you boot into the new system:\n\n# this command will get you into a GUI-like wifi connection system. \n# You can use it to connect to your wifi.\nnmtui"
  },
  {
    "objectID": "posts/arch-install/index.html#adding-a-user-and-giving-them-sudo-permission",
    "href": "posts/arch-install/index.html#adding-a-user-and-giving-them-sudo-permission",
    "title": "My first trial and error with installing Arch Linux",
    "section": "Adding a user and giving them sudo permission",
    "text": "Adding a user and giving them sudo permission\nWhen you are using the computer, it is very likely that you will be login yourself as some user. During the installtion, make sure you create a user using this command:\n\n# add user\nuseradd -m -G wheel -s /bin/bash [USERNAME]\n\n# create password for the user\npasswd [USERNAME]\n\n# give sudo permission to the user. \n# To do this, use the command below to go into the script and uncomment the section where it says \"uncomment to allow members of group wheel to execute any command.\"\nEDITOR=vim visudo"
  },
  {
    "objectID": "posts/arch-install/index.html#installing-grub",
    "href": "posts/arch-install/index.html#installing-grub",
    "title": "My first trial and error with installing Arch Linux",
    "section": "Installing GRUB",
    "text": "Installing GRUB\nAfter you have installed the system, you need to install GRUB to the disk. This is done by running the following command:1\n\ngrub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=GRUB\n\nYou also need to generate a configuration file for GRUB. To do that use the following command:\n\ngrub-mkconfig -o /boot/grub/grub.cfg"
  },
  {
    "objectID": "posts/arch-install/index.html#unmounting-all-the-drives",
    "href": "posts/arch-install/index.html#unmounting-all-the-drives",
    "title": "My first trial and error with installing Arch Linux",
    "section": "Unmounting all the drives",
    "text": "Unmounting all the drives\nAfter following all the installation steps, you need to unmount all the drives. This is done by running the following command:\n\n# unmount all the drives\numount -a"
  },
  {
    "objectID": "posts/arch-install/index.html#rebooting-the-system",
    "href": "posts/arch-install/index.html#rebooting-the-system",
    "title": "My first trial and error with installing Arch Linux",
    "section": "Rebooting the system",
    "text": "Rebooting the system\nAfter you have unmounted all the drives, you can reboot the system by running the following command:\n\n# reboot the system\nreboot"
  },
  {
    "objectID": "posts/arch-install/index.html#using-audio-and-bluetooth",
    "href": "posts/arch-install/index.html#using-audio-and-bluetooth",
    "title": "My first trial and error with installing Arch Linux",
    "section": "Using audio and bluetooth",
    "text": "Using audio and bluetooth\nYou need to install some packages to use the audio of the computer. I used pulseaudio but heard pipewire is something people use more nowadays.\nTo use bluetooth, you need to type following commands:\n\n# install packages necessary to use bluetooth\nsudo pacman -S bluez bluez-utils\n\n# enable the bluetooth system\nsudo systemctl enable bluetooth.service\n\n# start bluetooth interactive prompt to starting connecting your device\nbluetoothctl\n\n# turn on the power and do necessary steps before connecting\npower on\nagent on\ndefault-agent\n\n# turn on the scan to get the bluetooth ID for your device\nscan on\n\n# finish connecting the device\n# for some devices, you might have to enter password shown in the terminal\ntrust [BLUETOOTH ID]\npair [BLUETOOTH ID]\nconnect [BLUETOOTH ID]\n\n# After that, make sure you auto enable the bluetooth my going into the `/etc/bluetooth/main.conf` and uncomment the line that says `AutoEnable=true`."
  },
  {
    "objectID": "posts/arch-install/index.html#footnotes",
    "href": "posts/arch-install/index.html#footnotes",
    "title": "My first trial and error with installing Arch Linux",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI am using UEFI boot mode. If you are using BIOS boot mode, you need to use different command. Also, make sure to use the correct target and efi-directory that is specific to your system. It seems that sometimes this command works even if you don’t specify the target and efi-directory. But for me, I had to specify them.↩︎"
  },
  {
    "objectID": "posts/first-year/index.html",
    "href": "posts/first-year/index.html",
    "title": "First-year Ph.D. in retrospect",
    "section": "",
    "text": "We have nothing to declare except our ignorances.1\n\nRecently, my first-year PhD ended.2 Overall, it was an unique and a bizarre experience in a sense that I was in this whirlpool of the research frontier and the utmost ignorance. During my first-year, I had chances to experience the works of so many great minds. There were seminars everywhere. Periodically there would be some invited speakers whose papers I have read in my undergraduate or masters. Not only that, the school was constantly filled with people with interesting ideas and thoughts. Just talking to some upper years about their research projects made me excited. As someone once said, it was lucky to be alive to be in this time.\nBut this was not the only experience I had. First-year PhD was also the time when I was constantly reminded of my ignorance. Mingling with so many great people also made me realize how empty I am. Sometimes I was bit scared that I did not have much to say if someone asked me what my interests are. Although I was very interested in the field of economics, it was quite hard to exactly specify which part of economics I am interested and want to learn about.\nIn the end, I think first-year was a nice new start for me. It just made me realize that I am surrounded by so many great minds and that there is still so much things I have to do. So Back to mono it is."
  },
  {
    "objectID": "posts/first-year/index.html#back-to-mono-or-the-rabbit-hole",
    "href": "posts/first-year/index.html#back-to-mono-or-the-rabbit-hole",
    "title": "First-year Ph.D. in retrospect",
    "section": "",
    "text": "We have nothing to declare except our ignorances.1\n\nRecently, my first-year PhD ended.2 Overall, it was an unique and a bizarre experience in a sense that I was in this whirlpool of the research frontier and the utmost ignorance. During my first-year, I had chances to experience the works of so many great minds. There were seminars everywhere. Periodically there would be some invited speakers whose papers I have read in my undergraduate or masters. Not only that, the school was constantly filled with people with interesting ideas and thoughts. Just talking to some upper years about their research projects made me excited. As someone once said, it was lucky to be alive to be in this time.\nBut this was not the only experience I had. First-year PhD was also the time when I was constantly reminded of my ignorance. Mingling with so many great people also made me realize how empty I am. Sometimes I was bit scared that I did not have much to say if someone asked me what my interests are. Although I was very interested in the field of economics, it was quite hard to exactly specify which part of economics I am interested and want to learn about.\nIn the end, I think first-year was a nice new start for me. It just made me realize that I am surrounded by so many great minds and that there is still so much things I have to do. So Back to mono it is."
  },
  {
    "objectID": "posts/first-year/index.html#somethings-i-tried-to-do-in-my-first-year",
    "href": "posts/first-year/index.html#somethings-i-tried-to-do-in-my-first-year",
    "title": "First-year Ph.D. in retrospect",
    "section": "Somethings I tried to do in my first-year",
    "text": "Somethings I tried to do in my first-year\n\nSo, did I find my production function?: I think I did although it is kind of hard to formalize it in words.\nWhat is my work-life balance?: Personally, I think I am okay with working a lot as long as I can study or work in nice places time to time (cafes, beach, etc).\nWhat did I study?: Mostly core classes or course! I also personally studied about demand estimation in IO which I think was very helpful. At least now I think I kind of understand the process of BLP (in theory).\nRelationships: I have such a great time in Philly. I believe my cohorts and people around me are just awesome."
  },
  {
    "objectID": "posts/first-year/index.html#goal-for-the-second-year",
    "href": "posts/first-year/index.html#goal-for-the-second-year",
    "title": "First-year Ph.D. in retrospect",
    "section": "Goal for the second-year",
    "text": "Goal for the second-year\n\nStart doing more research: This is what I am paid to do anyway!\nFinding the research frontier: I still feel I am not quite sure of the literature frontier that I am on right now. Hopefully taking field courses and personal times will help me get a better sense of what that is."
  },
  {
    "objectID": "posts/first-year/index.html#footnotes",
    "href": "posts/first-year/index.html#footnotes",
    "title": "First-year Ph.D. in retrospect",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPersonal twist of the quotes by good ol’ Oscar Wilde.↩︎\nIn case you don’t know already, I am currently doing PhD in Applied Economics at The Wharton School, UPenn.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hyoungchul Kim",
    "section": "",
    "text": "I am a Ph.D. student in Applied Economics at The Wharton School, University of Pennsylvania.\nYou can either call me Hyoungchul (H-Young-Cheol, rhymes with “Null”) or Kent (my english name).\nI am currently interested in urban and environmental topics using tools from international trade and industrial organization.\nFor inquiries about software, email me or use the issue tracker at GitHub."
  },
  {
    "objectID": "posts/first-cite/index.html",
    "href": "posts/first-cite/index.html",
    "title": "First academic citation",
    "section": "",
    "text": "I just realized that I got my first-ever citation for one of my published papers.\n\n\n\nMy first citation\n\n\nIf getting a paper published is a first-order effect of academic achievement, I think having someone cite your paper is a second-order effect. In essence, I believe one of the main reasons we do academic research is to share it with other scholars and expand the current literature. In that sense, citation is important because it is an indicator that verifies that your research is (at least marginally) helping other scholars.\nThus, it is an epsilon leap for the academia, but a giant leap for myself."
  },
  {
    "objectID": "posts/admission-econ/index.html",
    "href": "posts/admission-econ/index.html",
    "title": "Admission tips for Econ. Ph.D. (by Ph.D. student)",
    "section": "",
    "text": "I had a chance to talk about some admission tips for master students in my university after my application process (It happened later year). I decided to share this slide on my website. You can find it here.\n\nDisclaimer\nThis slides only consist of my personal experience. That being said, lot of it can have some misinformation. Also, some of the contents are tailored to the students in my alma mater."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Blog",
    "section": "",
    "text": "My first trial and error with installing Arch Linux\n\n\n\nsoftware\n\n\n\nInstalling Arch Linux on Tuxedo Computers InfinityBook Pro 15\n\n\n\n\n\nJan 25, 2026\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nMy trial and error with Dockerfile\n\n\n\nsoftware\n\n\n\nThis is a post on my trial and error on building Docker image with Dockerfile\n\n\n\n\n\nSep 13, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on reproducible research workflow\n\n\n\nsoftware\n\n\n\nThis is a detailed post on how to use my replication template (or template for reproducible research workflow) in GitHub\n\n\n\n\n\nAug 30, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nOverTheWire wargames\n\n\n\nstudy\n\n\n\nPersonal solutions for overthewire wargames\n\n\n\n\n\nAug 2, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nAsahi-linux on Macbook Pro\n\n\n\nsoftware\n\n\n\nMy first experience with asahi-linux on Macbook Pro\n\n\n\n\n\nAug 2, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nFirst-year Ph.D. in retrospect\n\n\n\npersonal\n\n\n\nSummarizing my first-year Ph.D. in Economics experience\n\n\n\n\n\nJun 6, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nParallel programming\n\n\n\nstudy\n\n\n\nLearning basic parallel programming in R\n\n\n\n\n\nMay 26, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nMakefile: build automation software\n\n\n\nsoftware\n\n\n\nMaking automation workflow with Makefile\n\n\n\n\n\nApr 22, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nBeware of Bash\n\n\n\nsoftware\n\n\n\nSome warnings when using Bash\n\n\n\n\n\nMar 21, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nPersonal Dockerfile for data science\n\n\n\nsoftware\n\n\n\nPersonal Dockerfile template for my research workflow\n\n\n\n\n\nMar 15, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto format Econ. working paper template\n\n\n\nsoftware\n\n\n\nI just dropped a new quarto format working paper template in github\n\n\n\n\n\nMar 9, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nFirst academic citation\n\n\n\nresearch\n\n\n\nI am celebrating my first citation\n\n\n\n\n\nMar 1, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nAdmission tips for Econ. Ph.D. (by Ph.D. student)\n\n\n\nlecture\n\n\n\nAdmission tips slide I wrote for master students at Alma Mater\n\n\n\n\n\nJan 20, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nReproducible coding crash course\n\n\n\nlecture\n\n\n\nMy slide and resources on reproducible coding\n\n\n\n\n\nJan 20, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of my understanding of terms in empirical economics\n\n\n\nlecture\n\n\n\nSummary of some terms and jargons in the field of empirical economics\n\n\n\n\n\nJan 20, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nHello, Quarto\n\n\n\nannouncement\n\n\n\nMigrating from hugo github page\n\n\n\n\n\nJan 19, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\n\n\n\n\n\n\n\nSQL materials\n\n\n\nstudy\n\n\n\nResources for learning SQL\n\n\n\n\n\nJan 17, 2025\n\n\nHyoungchul Kim\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/reproducible-coding-lecture/index.html",
    "href": "posts/reproducible-coding-lecture/index.html",
    "title": "Reproducible coding crash course",
    "section": "",
    "text": "I recently did a crash course on “reproducible coding” at my alma mater. Here is my material for the course. It mostly deals with Bash, Project environment (Renv, Poetry), Automation (Make), Docker."
  },
  {
    "objectID": "posts/hello-quarto/index.html",
    "href": "posts/hello-quarto/index.html",
    "title": "Hello, Quarto",
    "section": "",
    "text": "Recently, I successfully migrated my website over to Quarto. My past website using Hugo1 was not that bad but it was bit too glitchy for me. Luckily, I was able to learn that it was possible to make a website using Quarto. After some trial and error, I was able to set it up.\nFor me, migrating was not that painful as I did not have much information on my website. In fact, this was partially due to the fragility of my past website. For some reason, my website would sometimes go full 404 when I commit new info on my website. In order to solve this, I had to make some meaningless changes to re-commit my git repository. This problem does not seem to occur in Quarto. Finally, I will be able to actively use my Blog section.\nFYI, I will write down some words about the problems I faced when migrating. I was bit stuck when I had to type quarto publish gh-pages. According to Quarto documentation, this code “will confirm that you want to publish, render your content, copy the output to a special gh-pages branch, push that branch to GitHub, and then open a browser to view your site once it is deployed.” The problem was that my command will not go through in the deployment process. The deployment will go on forever. I googled it and one of the solutions seems to be that I need to delete my gh-pages branch and old deployment point to re-initiate it. But I solved it by typing quarto publish gh-pages --no-browser. This is bit weird because Quarto documentation says you should use this option when you are publishing to a private website. While I don’t think my website is a private one, this somehow made my command go through.\nAlso, I had to specify gh-pages branch manually in the repo settings in the github repository."
  },
  {
    "objectID": "posts/hello-quarto/index.html#footnotes",
    "href": "posts/hello-quarto/index.html#footnotes",
    "title": "Hello, Quarto",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn case you want to check out my past hugo website, click here↩︎"
  },
  {
    "objectID": "posts/bandit/index.html",
    "href": "posts/bandit/index.html",
    "title": "OverTheWire wargames",
    "section": "",
    "text": "In this post, I write down my solutions for the OverTheWire wargames."
  },
  {
    "objectID": "posts/bandit/index.html#bandit",
    "href": "posts/bandit/index.html#bandit",
    "title": "OverTheWire wargames",
    "section": "Bandit",
    "text": "Bandit\n\n0\nJust get used to the concept of ssh. ssh is secure shell which allows secured access to the remote machine from the local computer.\n\nssh bandit0@bandit.labs.overthewire.org -p 2220\n\n# You will be asked to type in the password.\n\n\n\n0 to 1\n\n# print out the file\ncat readme\n\nexit\n \nssh bandit1@bandit.labs.overthewire.org -p 2220\n\n# You will be asked to type in the password.\n\n\n\n1 to 2\n\n# Special character - . Need to specify the full location of the file. \ncat ./-\n\n\n\n2 to 3\n\n# enclose the filenames using double quote, or use \\ before white space.\n\n\n\n3 to 4\n\n# list all files using -a argument\nls inhere/ -a\n\n\n\n4 to 5\n\n# find ASCII text files\n# -exec file {} + executes the file command to get info on the content\nfind inhere -type f -exec file {} + | grep ASCII\n\n\n\n5 to 6\n\nfind inhere -type f -size 1033c ! -executable -exec file {} + | grep ASCII\n\n\n\n6 to 7\n\n# since we don't know where the file is, we will search from the root directory\nfind / -user bandit7 -group bandit6 -size 33c -type f 2&gt;/dev/null -exec cat {} \\;\n\n\n\n7 to 8\n\ngrep -w \"millionth\" data.txt\n\n\n\n8 to 9\n\nsort data.txt | uniq -u data.txt\n\n\n\n9 to 10\n\nstrings data.txt | grep \"==\"\n\n\n\n10 to 11\n\ncat data.txt | base64 -d\n\n\n\n11 to 12\n\ncat data.txt | tr 'A-Za-z' 'N-ZA-Mn-za-m'\n\n\n\n12 to 13\n\nls\nhead data.txt\nmkdir /tmp/random_dir\ncd /tmp/random_dir\ncp ~/data.txt .\nmv data.txt data\nxxd -r data &gt; binary\nfile binary\nmv binary binary.gz\ngunzip binary.gz\nbunzip2 binary\nmv binary.out binary.gz\ngunzip binary.gz\ntar -xf binary\n\n# do similar procedure multiple times\nFO5dwFsc0cbaIiH0h8J2eUks2vdTDwAn\n\n\n\n13 to 14\n\nssh -i sshkey.private -p 2220 bandit14@localhost # This will log you in as user bandit14 and allow you to see the password.\n\n\n\n14 to 15\n\nnetcat localhost 30000\n# Then submit the password of the current level.\n\n\n\n15 to 16\n\nopenssl s_client -connect localhost:30001\n# Then submit the password of the current level.\n\n\n\n16 to 17\n\n# I feel this part is bit too complicated and not useful for me. So I just provide the link to someone else's solution\n# https://medium.com/@rushi.padhiyar098/overthewire-bandit-level-16-and-level-17-walkthrough-by-cyph3r-ryx-95c1ccdbb76b\n\n\n\n17 to 18\n\ndiff passwords.new passwords.old\n\n\n\n18 to 19\n\n# check shell other than bash\ncat /etc/shells\n\n# use it to login\nssh bandit18@bandit.labs.overthewire.org -p 2220 -t \"/bin/sh\"\n\ncGWpMaKXVwDUNgPAVJbWYuGHVn9zl3j8\n\n\n\n19 to 20\n\n./bandit20-do\n\n./bandit20-do ls /etc/bandit_pass\n\n./bandit20-do cat /etc/bandit_pass/bandit20\n\n\n\n20 to 21\n\n# I feel this part is not useful for me. So I just provide the link to someone else's solution\nEeoULMCra2q0dSkYj561DX7s1CpBuOBt"
  },
  {
    "objectID": "posts/empirical-econ/index.html",
    "href": "posts/empirical-econ/index.html",
    "title": "Summary of my understanding of terms in empirical economics",
    "section": "",
    "text": "I had some time last year to study about some terms and jargons used in empirical economics. I decided to share this slide on my website. You can find it here.\n\nDisclaimer\nThis is just a summary of the things I have read and studied. That being said, none of it should be credited as my work."
  },
  {
    "objectID": "posts/sql-info/index.html",
    "href": "posts/sql-info/index.html",
    "title": "SQL materials",
    "section": "",
    "text": "Here are some of the resources that I used (or plan to use) to understand SQL.\n\nSQL masterclass\nTeach SQL in grad school\nDuckDB and Polars\nTrue order of SQL\nSQL order of operations\nGoogle big query using R"
  },
  {
    "objectID": "posts/dockerfile-template/index.html",
    "href": "posts/dockerfile-template/index.html",
    "title": "Personal Dockerfile for data science",
    "section": "",
    "text": "Update: Recently I updated my Dockerfile for my research workflow. You can check it out here.\nDuring spring break, I had some time to finalize the Dockerfile template for my research workflow. If you don’t know what a Docker is, check it out here. TL;DR, it is a light virtual machine that contains all the necessary resources for your empirical analysis. It is as if you are shipping your computer to other people that wants to try out your analysis.\nIf you want the exact replication project folder, click here.\nThis is the final Dockerfile (for now):\n\n# Use Rocker image as the base for R\nFROM rocker/r-ver:4.4.0\n\nLABEL maintainer=\"Hyoungchul Kim &lt;hchul.kim96@gmail.com&gt;\"\n\n## Update and install system dependencies\nRUN apt-get update && apt-get install -y \\\n    libcurl4-openssl-dev \\\n    libssl-dev \\\n    libfontconfig1-dev \\\n    libharfbuzz-dev \\\n    libfribidi-dev \\\n    libfreetype6-dev \\\n    libpng-dev \\\n    libtiff5-dev \\\n    libjpeg-dev \\\n    libglpk-dev \\\n    libxml2-dev \\\n    libcairo2-dev \\\n    libgit2-dev \\\n    libpq-dev \\\n    libsasl2-dev \\\n    libsqlite3-dev \\\n    libssh2-1-dev \\\n    libxt-dev \\\n    libgdal-dev \\\n    wget \\\n    curl \\\n    vim \\\n    git \n\n## Install Pandoc and Quarto (Required for RMarkdown, Quarto, etc.)\n# RUN /rocker_scripts/install_pandoc.sh\n# RUN /rocker_scripts/install_quarto.sh\n\n## Install Python & Poetry\nRUN /rocker_scripts/install_python.sh && \\\n    pip3 install --upgrade pip && \\\n    pip3 install poetry\n\n# Ensure Poetry installs dependencies in the system environment\nRUN poetry config virtualenvs.create false\n\n# Copy Poetry files and install dependencies\nCOPY pyproject.toml poetry.lock .\nRUN poetry install --no-interaction --no-root\n\n## Install Julia 1.11.3 (to match Manifest.toml)\nENV JULIA_VERSION=1.11.3\nRUN /rocker_scripts/install_julia.sh\n\n## Set working directory\nWORKDIR /project\n\n## Copy renv.lock file into the folder\nCOPY renv.lock .\n\n# Set environment variables for renv\nENV RENV_VERSION=1.0.7\nENV RENV_PATHS_CACHE=/renv/cache\nENV RENV_CONFIG_REPOS_OVERRIDE=https://cloud.r-project.org\nENV RENV_CONFIG_AUTOLOADER_ENABLED=FALSE\nENV RENV_WATCHDOG_ENABLED=FALSE\nRUN echo \"options(renv.consent = TRUE)\" &gt;&gt; .Rprofile\nRUN echo \"options(RETICULATE_MINICONDA_ENABLED = FALSE)\" &gt;&gt; .Rprofile\n\n# Install renv from CRAN (avoiding bootstrapping by specifying version)\nRUN R -e \"install.packages('renv', repos = c(CRAN = 'https://cloud.r-project.org'))\"\nRUN R -e \"renv::consent(provided = TRUE)\"\n\n# Run renv restore to restore the environment\nRUN R -e \"renv::restore(confirm = FALSE)\"\n\n# Install Julia packages and manage dependencies\nCOPY Manifest.toml Project.toml .\nENV JULIA_PROJECT=/project\nRUN julia -e \"import Pkg; Pkg.activate(\\\".\\\"); Pkg.instantiate()\"\n\n# Copy over the rest of the project files\nCOPY . .\n\n# Default command\nCMD [\"bash\"]\n\nAlthough most of the commands are self-explanatory from the comments, here is some additional info on what my Dockerfile does:\n\nIn my personal Dockerfile, I have added three major programming languages that I use: R, Python, and Julia.\nI have also added some necessary dependencies and useful programs (e.g. git, vim) for my analysis.\nI have also added dependency management software for all of the languages. renv for R, poetry for Python, and Pkg environment for Julia. This allows you to use the exact versions of the packages that you installed in your analysis.\nFor this code to fully work, you would need to setup some files (e.g. Project.toml, Manifest.toml, etc).\nSave the above code as Dockerfile (no extensions) right inside your project directory.\n\n\nQuick terminology\n\nDockerfile: “The sheet music.” The list of layers and instructions for building a Docker image.\nImage: “The MP3 file.” This is the tarball.\nContainer: “Song playing on my phone.” A container is a running instance of an image.\n\n\n\nDocker workflow\n\nCreate Dockerfile.\nBuild Docker image using Dockerfile.\n\n\n# IMPORTANT: If this does not go through, maybe try sudo command\ndocker build --network=host --tag &lt;PROJECT_NAME&gt;:VERSION . \n\n# Above command might not work well in computers such as Macbook with Apple Silicon (Ofc...). This is mainly because it has a different cpu architecture (arm64 instead of amd64) so the base image is different. I am not sure if this is the best solution but try this code below.\n# docker build --platform=linux/amd64 --tag &lt;PROJECT_NAME&gt;:VERSION .\n\n\nRun Docker image.\n\n\ndocker run -it --rm &lt;PROJECT_NAME&gt;:VERSION\n\n\n\nSome useful Docker-related commands\n\n# check cached docker images\ndocker images\n\n# check docker containers that are running\ndocker ps\n\n# remove the docker image\ndocker rmi &lt;IMAGE_NAME&gt;\n\n# remove all dangling images and caches (do it periodically to save space)\ndocker system prune"
  },
  {
    "objectID": "research-idea/index.html",
    "href": "research-idea/index.html",
    "title": "Research idea checklist",
    "section": "",
    "text": "High-level (at least two for JMP, one for decent paper)\n\nNew? (literature frontier).\nInteresting? (Real-world relevance, policy implementation).\nData? (New data).\n\n\n\nRQ specification\n\nFind concrete real-life example or policy.\nCheck data.\nSpecify trade-off.\nSpecify the setting (agents, outcomes, etc).\nSpecify potential research design (identification).\nSpecify simple economic model.\n\n\n\nFinal checklist\n\nTalk to other PhDs.\nTalk to faculties (2+).\nPresent preliminary ideas."
  },
  {
    "objectID": "misc/personal/econ7100.html",
    "href": "misc/personal/econ7100.html",
    "title": "ECON-7100",
    "section": "",
    "text": "This is an informal note to record what I thought about or what I thought was important in the Microeconomics I class.\n\ntba"
  },
  {
    "objectID": "misc/personal/econ7200.html",
    "href": "misc/personal/econ7200.html",
    "title": "ECON-7200",
    "section": "",
    "text": "This is an informal note to record what I thought about or what I thought was important in the Macroeconomics I class.\n\nCompetitive eqm, efficiency, and GE\nI don’t know why, but I always feel that macro course does a better job of explaining the concep of GE, competitive eqm, and the welfare theorem than the second portion of micro course. It was nice to see how we start with simple Arrow-Debreu setup and derive the competitive equilibrium. Then we use welfare theorem to connect the competitive eqm to pareto efficiency.\n\n\nDynamics"
  },
  {
    "objectID": "misc/personal/working-environment.html",
    "href": "misc/personal/working-environment.html",
    "title": "Setting up working environment",
    "section": "",
    "text": "Preface\nThis is just a note for myself to re-setup my working environment on Linux (I am using Ubuntu) so that I don’t forget what I need to do.\n\n\nTerminal\n\nInstall fastfetch\n\nsudo add-apt-repository ppa:fastfetch/stable\nsudo apt install fastfetch \n\n# add `fastfetch` in `.bashrc` file.\n\n\n\n\nVim\n\nInstall Vim and set it as default text editor\n\nsudo apt update\nsudo apt install vim\n\nsudo update-alternatives --config editor\n\n\n\nInstall Vim-plugin\nFollow this link: LINK\nSome plugins I use (Example of .vimrc file)\n\ncall plug#begin()\n\n\" List your plugins here\nPlug 'sirver/ultisnips'\nPlug 'lervag/vimtex'\nPlug 'KeitaNakamura/tex-conceal.vim'\nPlug 'arcticicestudio/nord-vim'\nPlug 'preservim/nerdtree'\n\ncall plug#end()\n\nlet g:UltiSnipsExpandTrigger = '&lt;tab&gt;'\nlet g:UltiSnipsJumpForwardTrigger = '&lt;tab&gt;'\nlet g:UltiSnipsJumpBackwardTrigger = '&lt;s-tab&gt;'\nlet g:vimtex_view_method = 'zathura'\nlet g:vimtex_quickfix_mode = 0\nlet g:lightline = {'colorscheme' : 'nord'}\n\nsetlocal spell\nset spelllang=en_us\ninoremap &lt;C-l&gt; &lt;c-g&gt;u&lt;Esc&gt;[s1z=`]a&lt;c-g&gt;u\n\ncolorscheme nord\n\n\n\nSetup Vimtex with zathura\nFollow this: https://github.com/lervag/vimtex. Also remember that you need to install separate tex compiler to use tex.\n\n\n\nInstall R\nJust follow this site: https://pmassicotte.github.io/linux-mint-dev-environment/installr.html.\nI will just post my current .Rprofile file for reference:\n\nif (interactive() && Sys.getenv(\"RSTUDIO\") == \"\") {\n  Sys.setenv(TERM_PROGRAM = \"vscode\")\n  if (\"httpgd\" %in% .packages(all.available = TRUE)) {\n    options(vsc.plot = FALSE)\n    options(device = function(...) {\n      httpgd::hgd(silent = TRUE)\n      .vsc.browser(httpgd::hgd_url(history = FALSE), viewer = \"Beside\")\n    })\n  }\n  source(file.path(Sys.getenv(if (.Platform$OS.type == \"windows\") \"USERPROFILE\" else \"HOME\"), \".vscode-R\", \"init.R\"))\n}\n\n# Connect to public package manager\noptions(repos = c(CRAN = \"https://packagemanager.posit.co/cran/__linux__/rhel9/latest\"))\n\n# This is important if you are using RSPM on Linux outside RStudio\noptions(HTTPUserAgent = sprintf(\"R/%s R (%s)\", getRversion(), paste(getRversion(), R.version[\"platform\"], R.version[\"arch\"], R.version[\"os\"])))"
  },
  {
    "objectID": "misc/personal/seoul.html",
    "href": "misc/personal/seoul.html",
    "title": "Travel tips and recommendations",
    "section": "",
    "text": "IMPORTANT: Summer in Korea is very hot and humid! When planning outdoor activities make sure you check out the weather beforehand. Fortunately, most buildings in Korea have ACs so try to stay indoor a lot during the summer.\nIn general, “information friction” seems to be quite low in South Korea. That being said, be aware that popular places that you search for on the internet will be quite crowded. Do expect some queue lines and make sure you consider the tradeoff of visiting a nice place and spending lot of time in the queue (But also take into account that most good places will have large volume of people on average. So you will need to wait in most places you want to visit).\nMaps: Like many other East Asia countries, lot of systems in Korea are country-specific (unfortunately). If you tend to travel in Korea, I strongly recommend you download either “Naver map” or “Kakao map” on your phone. They are the google map equivalent app in Seoul. Note that google map will not work very well in Korea.\nTransportation card: Unfortunately, you cannot use your regular credit cards to pay for the public transportation. You will have to buy some pre-paid card. For short-term trips, you can buy them at the station. I recommend you try out Climate card which is a relatively new pre-paid pass card that came out in Seoul. Also, remember to TAP IN and TAP OUT on both buses and subways!\nOrdering in restaurant: In Korea, there is no tip culture. That being said, no servers are assigned to your table (like in US). So do not passively wait for them to come get your order. In Korea, you can just call the server by raising your hand and calling out “excuse me”. This is not considered impolite and you will see that many people do that. Otherwise, they are not going to periodically check on you. Also, unlike other countries, you don’t pay the bill in your table. When you are done eating, just go to the counter and pay for the meal.\nPublic safety: I would say Seoul is one of the most safe cities in the world(in terms of traveling). You don’t need to worry too much about where you are going (within Seoul, it will be very unlikely that you stumble into some dangerous regions) and you can walk around at night. Many people will just walk around Seoul at 2, 3am and it would be fine.\nDrinking: One nice thing about Korea’s drinking culture is that you can drink your bottle outside. I would suggest you take some night-time picnic to Hangang river with some drinks. There are lot of parks near the river where you will see people drinking and enjoying the view.\nBicycle: Seoul also has public bicycle system. I didn’t try it often but I heard it’s pretty good. But warning: Unlike US or European countries, there are not many lanes strictly designated to bicycle in Korea. Also, it is bit rare for bicycle to go on the same road with the cars. In fact, it will be more common to just ride the bicycle in the pedestrian way. So when traveling in bicycle, just use the pedestrian way and be careful of the people. You should also keep an eye on the street for bicycle as you walk."
  },
  {
    "objectID": "misc/personal/seoul.html#general-tips",
    "href": "misc/personal/seoul.html#general-tips",
    "title": "Travel tips and recommendations",
    "section": "",
    "text": "IMPORTANT: Summer in Korea is very hot and humid! When planning outdoor activities make sure you check out the weather beforehand. Fortunately, most buildings in Korea have ACs so try to stay indoor a lot during the summer.\nIn general, “information friction” seems to be quite low in South Korea. That being said, be aware that popular places that you search for on the internet will be quite crowded. Do expect some queue lines and make sure you consider the tradeoff of visiting a nice place and spending lot of time in the queue (But also take into account that most good places will have large volume of people on average. So you will need to wait in most places you want to visit).\nMaps: Like many other East Asia countries, lot of systems in Korea are country-specific (unfortunately). If you tend to travel in Korea, I strongly recommend you download either “Naver map” or “Kakao map” on your phone. They are the google map equivalent app in Seoul. Note that google map will not work very well in Korea.\nTransportation card: Unfortunately, you cannot use your regular credit cards to pay for the public transportation. You will have to buy some pre-paid card. For short-term trips, you can buy them at the station. I recommend you try out Climate card which is a relatively new pre-paid pass card that came out in Seoul. Also, remember to TAP IN and TAP OUT on both buses and subways!\nOrdering in restaurant: In Korea, there is no tip culture. That being said, no servers are assigned to your table (like in US). So do not passively wait for them to come get your order. In Korea, you can just call the server by raising your hand and calling out “excuse me”. This is not considered impolite and you will see that many people do that. Otherwise, they are not going to periodically check on you. Also, unlike other countries, you don’t pay the bill in your table. When you are done eating, just go to the counter and pay for the meal.\nPublic safety: I would say Seoul is one of the most safe cities in the world(in terms of traveling). You don’t need to worry too much about where you are going (within Seoul, it will be very unlikely that you stumble into some dangerous regions) and you can walk around at night. Many people will just walk around Seoul at 2, 3am and it would be fine.\nDrinking: One nice thing about Korea’s drinking culture is that you can drink your bottle outside. I would suggest you take some night-time picnic to Hangang river with some drinks. There are lot of parks near the river where you will see people drinking and enjoying the view.\nBicycle: Seoul also has public bicycle system. I didn’t try it often but I heard it’s pretty good. But warning: Unlike US or European countries, there are not many lanes strictly designated to bicycle in Korea. Also, it is bit rare for bicycle to go on the same road with the cars. In fact, it will be more common to just ride the bicycle in the pedestrian way. So when traveling in bicycle, just use the pedestrian way and be careful of the people. You should also keep an eye on the street for bicycle as you walk."
  },
  {
    "objectID": "misc/personal/seoul.html#transportation-tips",
    "href": "misc/personal/seoul.html#transportation-tips",
    "title": "Travel tips and recommendations",
    "section": "Transportation tips",
    "text": "Transportation tips\n\nAirport to Seoul (bus): There are few ways to go from Incheon international airport to Seoul. Easiest way (but little bit more expensive) is airport bus (a.k.a. limousine bus). You can buy the ticket in the airport and they cover most major places in Seoul. You can also use the subway although I have never tried it.\nTransportation within Seoul (bus and subway): If you stay in Seoul, you will be able to access most (to be honest, all) locations in the city using public transportation. Main transportation is “bus” and “subway.” Another advantage of Seoul is that bus and subway system are very well interconnected. You only pay by the distance (even the rate of increment for distance is pretty generous within Seoul) and transferring to other bus or subway do not have extra cost (except very few subway or system run by different region). Arrival rates are also pretty good so make sure you use it a lot.\nTransportation at night (taxi): That being said, you won’t need to use other transportation within Seoul unless you are moving very late at night. Lot of subways and buses stop working around 11pm~12am-ish. If you tend to stay far away from your home at night, you will have to use taxi. You can get a taxi either by catching them on the go or by app (sth like kakao taxi). Just be warned that it is bit harder to catch taxi at night as there are less supply."
  },
  {
    "objectID": "misc/personal/seoul.html#general-travel-places-recommendation",
    "href": "misc/personal/seoul.html#general-travel-places-recommendation",
    "title": "Travel tips and recommendations",
    "section": "General travel places recommendation",
    "text": "General travel places recommendation\n\nOfficial visitor guide: LINK\nFor full lists of places you can go, try out this LINK"
  },
  {
    "objectID": "misc/personal/seoul.html#brief-personal-recommendations",
    "href": "misc/personal/seoul.html#brief-personal-recommendations",
    "title": "Travel tips and recommendations",
    "section": "Brief personal recommendations",
    "text": "Brief personal recommendations\n\nPlaces around “seoul forest” are quite nice. The park is very nice with small pond and place near the park (Seongsu-dong) has sort of New York Brooklyn vibe(shameless comparison, I know…). Just be aware that there tends to be lot of people around.\nTry out places around the old city. These places are generally called “within four doors.” This is because in the past, the Seoul walled city had four main doors for entry. Unlike other places in Seoul which are now pretty modern, old city area still has lot of traditional places. Try out some traditional Korean house villages (like Bukchon Hanok Village and Seochon). I personally like area around Seochon. They are also close to the palaces so you will be able to visit them as well. Overall, area around the palaces (Seochon or Bukchon are all places surrounding the old palaces) are generally nice place to walk around.\nWalking along the river is nice. Especially try out Cheong-gye-cheon stream at night. Having a night picnic near Han-gang river is also a nice experience.\nIf you like theme parks, be sure to try out Lotte World Adventure. It used to be the biggest In-door Theme park until 2010. It is also known for having many dark rides. It is also close to shopping mall (Lotte mall is right next to it) and Lotte World Tower which is currenlty the tallest building in Korea.1\n\n\nTry out some traditional markets: Places like Gwang-jang market or Tong-in market are very interesting places to go and eat some snack foods.\nIf you have time, you could go to Sinchon which has university (Yonsei University) I am from. Although it is not as fancy as universities in Europe or US, it is overall clean and nice. Even though place is bit dying now, Sinchon is also known as one of the popular places for university students. You will be able to feel some freshman(?) vibe.2\n\n\nAlthough not my favorite, I guess you will probably be visiting Gangnam at least once when you are in Seoul. It is sort of like SOHO in UK. I do think it is a bit tourist-trap place but it does have some nice restaurants and places.\nIf you are a “park person”, try out Olympic park. It is also pretty close to Seok-chon lake which is also a famous place for a walk. But note that the place might be packed with people depending on when you go.\nKorea also has some nice coffee shops so try them. Good thing about cafes in Korea is that it is very convenient to work (e.g. using laptop). Lot of coffee shops in Korea have large tables and power outlets around."
  },
  {
    "objectID": "misc/personal/seoul.html#personal-food-recommendations",
    "href": "misc/personal/seoul.html#personal-food-recommendations",
    "title": "Travel tips and recommendations",
    "section": "Personal food recommendations",
    "text": "Personal food recommendations\n\nKorean BBQ: I think Korean BBQ is now quite popular even outside of Korea. Big advantage of eating Korean BBQ in Korea is that it is relatively cheaper. If you have time, try places like “ha-nam pig house”, “Go-ban sik-dang”, “byeok-je kalbi”, etc.\nKorean fried chicken: Korean fried chicken is very tasty. There are many places (e.g. BBQ chicken, BHC chicken, etc) you can get it from and they all have their own specialties. I recommend you get a take-out and eat it near Han-gang river with some beer.\nCold noodles (e.g. Pyeong-yang Neng-myeon): Korea also has nice cold noodles. Peyong-yang Neng-myeon is my favorite but opinions are divided (some people don’t like it because it tastes quite bland). Try places like “ure-ok”, “bong-phee-yang”, “ul-ji-myeon-ok”, “ul-mil-dae”. Other than Pyeong-yang Neng-myeon, bean noodle is also a nice choice. It is basically noodle served in a soup made from grinding beans.\nTraditional Korean food: Unlike course style cuisine in other countries, interesting aspect about korean cuisine is that it is usually served all at once. So when you order some food, it will be served with other side dishes (usually called “ban-chan”). Also good thing about this side dishes is that you can ask a refill for these side dishes for free. Be sure you go to some traditional Korean food restaurant to check out these dishes."
  },
  {
    "objectID": "misc/personal/seoul.html#footnotes",
    "href": "misc/personal/seoul.html#footnotes",
    "title": "Travel tips and recommendations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt also holds few other records: (1) 8th tallest building in the world, (2) Tallest building out of all OECD countries.↩︎\nJust be careful not to confuse Sinchon with Sincheon. The one I am referring to is located in the north of the river. On the other hand, Sincheon is located in the south.↩︎"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "“The China shock and internal migration: evidence from bilateral migration flows” with Jaerim Choi and Seung Hoon Lee. Mar. 2025. [Working paper]. Revise and Resubmit, Canadian Journal of Economics.\n\n\nAbstract\n\nUsing Korean administrative datasets spanning almost two decades and covering nearly the entire bilateral internal migration flows between local labor markets, we identify the causal impact of the China trade shock on internal migration. The trade shock affects in-migration, but not out-migration. Separating further the China trade shock into export and import shocks, we find that export expansion increases in-migration, whereas import competition reduces in-migration. By decomposing the impact of trade shock into age groups, we find that effects of trade shocks in destination are robust and statistically significant across age groups; and most pronounced for middle-aged people between the ages of 45 and 64. Finally, households with male heads are more likely to be influenced by the trade shock compared to those with female heads, due to the greater reliance of the manufacturing sector on male labor."
  },
  {
    "objectID": "research/index.html#working-papers",
    "href": "research/index.html#working-papers",
    "title": "Research",
    "section": "",
    "text": "“The China shock and internal migration: evidence from bilateral migration flows” with Jaerim Choi and Seung Hoon Lee. Mar. 2025. [Working paper]. Revise and Resubmit, Canadian Journal of Economics.\n\n\nAbstract\n\nUsing Korean administrative datasets spanning almost two decades and covering nearly the entire bilateral internal migration flows between local labor markets, we identify the causal impact of the China trade shock on internal migration. The trade shock affects in-migration, but not out-migration. Separating further the China trade shock into export and import shocks, we find that export expansion increases in-migration, whereas import competition reduces in-migration. By decomposing the impact of trade shock into age groups, we find that effects of trade shocks in destination are robust and statistically significant across age groups; and most pronounced for middle-aged people between the ages of 45 and 64. Finally, households with male heads are more likely to be influenced by the trade shock compared to those with female heads, due to the greater reliance of the manufacturing sector on male labor."
  },
  {
    "objectID": "research/index.html#publications",
    "href": "research/index.html#publications",
    "title": "Research",
    "section": "Publications",
    "text": "Publications\n[2] “Does political conflict hurt immigration? Evidence from the South Korea – China THAAD Dispute” with Jongkwan Lee. Aug. 2024. Published in Southern Economic Journal [Paper].\n[1] “The well-being of cities: estimating migration attractiveness from internal migration across Korean cities” with Seung Hoon Lee and Ji Sub Park. Feb. 2024. Published in Global Economic Review [Paper]."
  },
  {
    "objectID": "research/index.html#work-in-progress",
    "href": "research/index.html#work-in-progress",
    "title": "Research",
    "section": "Work in progress",
    "text": "Work in progress\n\n“Investment and deforestation under uncertain market access: evidence from the Mexican avocado boom” with Prakash Mishra, Sebastian Sardon and James E. Sayre"
  },
  {
    "objectID": "research/index.html#other-works",
    "href": "research/index.html#other-works",
    "title": "Research",
    "section": "Other works",
    "text": "Other works\n[1] A comment on “Malaria suitability, urbanization and persistence: Evidence from China over more than 2000 years” with Marc Joëts, Stefania Lovo and Niklas Murken. Nov. 2025. UKRN replication game. Institute for Replication. [Paper]"
  }
]