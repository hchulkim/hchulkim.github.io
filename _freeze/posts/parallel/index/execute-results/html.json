{
  "hash": "9faca7b4121fbf19c229067208ceba5f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Parallel programming\"\ndescription: \"Learning basic parallel programming in R\"\ndate: \"2025-05-26\"\ntoc: false\nengine: knitr\ncategories:\n  - study\n---\n\n\n\n\nIn this post, I write down the materials I studied on parallel programming. All the things below are from [Grant McDermott's lecture](https://raw.githack.com/uo-ec607/lectures/master/12-parallel/12-parallel.html) so none of it should be credited as my work. It is just a reminder post for applying parallel programming.\n\n## Load packages\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Load and install the packages that we'll be using today\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tictoc, parallel, pbapply, future, future.apply, tidyverse, \n               hrbrthemes, furrr, RhpcBLASctl, memoise, here)\n## My preferred ggplot2 plotting theme (optional)\ntheme_set(hrbrthemes::theme_ipsum())\n\n## Set future::plan() resolution strategy\nplan(multisession)\n```\n:::\n\n\n\n\n## Example 1\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(tidyverse) ## Already loaded\n\n## Emulate slow function\nslow_square = \n  function(x = 1) {\n    x_sq = x^2 \n    d = tibble(value = x, value_squared = x_sq)\n    Sys.sleep(2)\n    return(d)\n    }\n\n# library(tictoc) ## Already loaded\n\ntic()\nserial_ex = lapply(1:12, slow_square) %>% bind_rows()\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n24.084 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# future::availableCores() ## Another option\ndetectCores()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10\n```\n\n\n:::\n:::\n\n\n\n\n**Use `future.apply`**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(future.apply)  ## Already loaded\n# plan(multisession)     ## Already set above\n\ntic()\nfuture_ex = future_lapply(1:12, slow_square) %>% bind_rows()\ntoc(log = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n6.711 sec elapsed\n```\n\n\n:::\n:::\n\n\n\n\nExecution time has greatly reduced! The results are also equivalent:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall.equal(serial_ex, future_ex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\n`purrr` package also has something similar:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(furrr)      ## Already loaded\n# plan(multisession)  ## Already set above\n\ntic()\nfurrr_ex = future_map(1:12, slow_square) |> list_rbind()\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n5.098 sec elapsed\n```\n\n\n:::\n:::\n\n\n\n\n## Example 2\n\nThis is another example. I will not run this to save rendering time.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Set seed (for reproducibility)\nset.seed(1234)\n# Set sample size\nn = 1e6\n\n## Generate a large data frame of fake data for a regression\nour_data = \n  tibble(x = rnorm(n), e = rnorm(n)) %>%\n  mutate(y = 3 + 2*x + e)\n\n## Function that draws a sample of 10,000 observations, runs a regression and\n## extracts the coefficient value on the x variable (should be around 2).\nbootstrp = \n  function(i) {\n  ## Sample the data\n  sample_data = sample_n(our_data, size = 1e4, replace = TRUE)\n  ## Run the regression on our sampled data and extract the extract the x\n  ## coefficient.\n  x_coef = lm(y ~ x, data = sample_data)$coef[2]\n  ## Return value\n  return(tibble(x_coef = x_coef))\n  }\n\nset.seed(123L) ## Optional to ensure that the results are the same\n\n## 10,000-iteration simulation\ntic()\nsim_serial = lapply(1:1e4, bootstrp) %>% bind_rows()\ntoc(log = TRUE)\n\n# Takes about 36 seconds.\n```\n:::\n\n\n\n\n## Summary of parallel programming packages in `R`\n\n`future` ecosystem is very useful. It provides simple and unified approach to implementing parallel programming. You can usually apply this ecosystem by using `future.apply` or `furrr` package.\n\n## If in Linux or Mac, try forking!\n\nThere two different ways to run parallel programming:\n\nforking| parallel sockets (PSOCKS)\n-----|:-----\nFast and memory efficient.|Slower and more memory-intensive (than forking).\nOnly available for Unix-based systems.|Works on every operating system, incl. Windows.\nPotentially unstable in an IDE like RStudio.|Fine to use in an IDE like RStudio.\n\n**How to do this**\n\n1. Change your resolution plan to `plan(multicore)`, and\n2. Run your R script from the terminal using, say, `$ Rscript -e 'rmarkdown::render(\"mydoc.Rmd\", \"all\")'` or `$ Rscript myfile.R`.\n\n## Implicit parallel programming\n\nSome packages actually apply parallel programming implicitly (e.g. `data.table`). So in this case, you might not need to resort too much in explicit parallel programming.\n\n## Setting how many cores to use\n\n`plan(multisession)` or `plan(multicore)` automatically default to using all your cores. You can change that by running, say, `plan(multisession(workers = detectCores()-1))`.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}